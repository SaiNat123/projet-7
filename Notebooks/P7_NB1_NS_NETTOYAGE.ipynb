{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t3gnHeFON-8g"
   },
   "outputs": [],
   "source": [
    "''# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os, sys\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez_HLhNIN0j4"
   },
   "source": [
    "## Téléchargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "qEMpSQDDOPwX",
    "outputId": "5fd320a4-7c93-4055-b792-845eec23b9b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\application_train.csv')\n",
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (48744, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_test = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\application_test.csv')\n",
    "print('Training data shape: ', app_test.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2li1nlyFlZZe"
   },
   "source": [
    "application_train/application_test : les principales données de formation et de test avec des informations sur chaque demande de prêt chez Home Credit. Chaque prêt a sa propre ligne et est identifié par la caractéristique SK_ID_CURR. Les données de la demande de formation sont accompagnées de la CIBLE indiquant 0 : le prêt a été remboursé ou 1 : le prêt n'a pas été remboursé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zgto7HXaDYG",
    "outputId": "dfc5838f-9ee6-4e38-a7b3-b2218bc2376e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app previous Shape: (1670214, 37)\n",
      "installments payments Shape: (13605401, 8)\n",
      "sample submission Shape: (48744, 2)\n",
      "bureau Shape: (1716428, 17)\n",
      "bureau balance Shape: (27299925, 3)\n",
      "POS CASH balance Shape: (10001358, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app_previous = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\previous_application.csv')\n",
    "print(f'app previous Shape: {app_previous.shape}')\n",
    "\n",
    "installments_payments = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\installments_payments.csv')\n",
    "print(f'installments payments Shape: {installments_payments.shape}')\n",
    "\n",
    "sample_submission = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\sample_submission.csv')\n",
    "print(f'sample submission Shape: {sample_submission.shape}')\n",
    "\n",
    "bureau = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\bureau.csv')\n",
    "print(f'bureau Shape: {bureau.shape}')\n",
    "\n",
    "bureau_balance = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\bureau_balance.csv')\n",
    "print(f'bureau balance Shape: {bureau_balance.shape}')\n",
    "\n",
    "POS_CASH_balance = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\POS_CASH_balance.csv')\n",
    "print(f'POS CASH balance Shape: {POS_CASH_balance.shape}')\n",
    "\n",
    "credit_card_balance = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\credit_card_balance.csv')\n",
    "print(f'credit card balance Shape: {credit_card_balance.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "PLL3W5h9WlZB",
    "outputId": "f982356f-c4aa-4550-cbe7-bde6e3be18ee"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "app_train.dtypes.value_counts().plot.pie(explode=(0, 0, 0.2),autopct='%1.1f%%', colors=['#BD98FB','#B7BCFF', '#AEE7F2'],shadow=True)\n",
    "plt.title(\"Types de données\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WbBqpun2dbS"
   },
   "source": [
    "# Analyse Exploratoire\n",
    "La cible est ce qu'on nous demande de prévoir : soit un 0 pour le prêt a été remboursé à temps, soit un 1 indiquant que le client a eu des difficultés de paiement. Nous pouvons d'abord examiner le nombre de prêts entrant dans chaque catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8VFT0dIRmkh",
    "outputId": "cf7e4840-283a-4bac-a36f-e53225a4e127"
   },
   "outputs": [],
   "source": [
    "app_train['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "3eNgwsg63h5i",
    "outputId": "69d4d404-3405-4766-e7d6-ab66c006daa7"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=app_train['TARGET'], palette=['#BD98FB', '#AEE7F2'])\n",
    "total = len(app_train['TARGET'])\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_height() / total)\n",
    "    x = p.get_x() + p.get_width() / 2 - 0.1\n",
    "    y = p.get_height()\n",
    "    ax.annotate(percentage, (x, y), ha='center', fontsize=12, color='black')\n",
    "sns.despine()\n",
    "plt.suptitle('Distribution of the Target Column', fontsize=12)\n",
    "plt.title('0 = loan was repaid on time,    1 = client had payment difficulties.', fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY33f_kq4mT1"
   },
   "source": [
    "## Valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsWIFUPg4BMa",
    "outputId": "70d89fc6-3ff0-44f9-8e8b-70eb964680ec"
   },
   "outputs": [],
   "source": [
    "print(app_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IE66sA-P-3_P",
    "outputId": "0a9d4269-16a4-48d3-a15d-94564c71c95d"
   },
   "outputs": [],
   "source": [
    "app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HerPTZ5WApLg",
    "outputId": "f1cd42da-8be9-4cff-c77a-e6c9e0ea364d"
   },
   "outputs": [],
   "source": [
    "# Nombre de classes uniques dans chaque colonne d'objet \n",
    "app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMC8K76d44Zh"
   },
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "y8IqsteR5N5Q",
    "outputId": "283230c9-c1ad-471c-e77e-6b62cd1ca9e7"
   },
   "outputs": [],
   "source": [
    "missing_values = missing_values_table(app_train)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_QsQEwu8vJ4",
    "outputId": "46b4d2e9-893e-4c8c-c977-a912d8523d32"
   },
   "outputs": [],
   "source": [
    "missing_values.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKixfRpUOg3r"
   },
   "outputs": [],
   "source": [
    "def plot_feat(df:pd.DataFrame,feature:str,label_rotation=False,horizontal_layout=True):\n",
    "    temp = df[feature].fillna('Unknown').value_counts()\n",
    "    df1 = pd.DataFrame({feature: temp.index,'Number of contracts': temp.values})\n",
    "    df1.sort_values(by=feature, inplace=True)\n",
    "\n",
    "    # Calculate the percentage of each category with target=1\n",
    "    cat_perc = df[[feature, 'TARGET']].fillna(\"Unknown\").groupby([feature],as_index=False).mean()\n",
    "    cat_perc['TARGET']*=100\n",
    "    cat_perc.sort_values(by=feature, inplace=True)\n",
    "    \n",
    "    if(horizontal_layout):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14))\n",
    "    s = sns.barplot(ax=ax1, x = feature, y=\"Number of contracts\",data=df1, color = 'blue')\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    ax1.set_title('Nombre de contrats par catégorie')\n",
    "    sns.despine()\n",
    "\n",
    "    s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc, color = 'green')\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    ax2.set_ylabel('Pourcentage de la catégorie avec target valeur 1 [%]')\n",
    "    ax2.set_title('Pourcentage de prêts en défaut de paiement')\n",
    "    sns.despine()\n",
    "\n",
    "    plt.suptitle(f\"Contrats par catégorie de fonctionnalité '{feature}'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "9CXOyGUCOMQQ",
    "outputId": "1488b20a-9f9c-4c7b-8b37-26a5bf9b0f20"
   },
   "outputs": [],
   "source": [
    "# Type de contrat\n",
    "plot_feat(app_train, 'NAME_CONTRACT_TYPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2dTmESoqyTY"
   },
   "source": [
    "On peut voir que la plupart des prêts que les clients prennent sont des prêts cash.\n",
    "moin 6% des personnes ont contracté un prêt revolving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "O7dA9R5SOMbj",
    "outputId": "f64551ab-8045-40d8-e91b-cdabd86d4ce9"
   },
   "outputs": [],
   "source": [
    "plot_feat(app_train, 'CODE_GENDER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoP1btMur5b4"
   },
   "source": [
    "Le premier point à observer est qu'il y a 4 lignes dans la table application_train qui ont des genres \"XNA\".\n",
    "Dans le subplot 1, nous constatons que pour l'ensemble de données donné, il y a plus de candidats féminins  que de candidats masculins.\n",
    "Cependant, contrairement au nombre de candidates, nous constatons, à partir du deuxième subplot, que les candidats masculins ont tendance à être plus défaillants (10,14%) que les candidates féminines (7%).\n",
    "Ainsi, on peut dire que les hommes ont plus tendance à ne pas payer leurs dettes que les femmes selon l'ensemble de données donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuQ3VDSsDn20"
   },
   "outputs": [],
   "source": [
    "# Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "app_train = app_train[app_train['CODE_GENDER'] != 'XNA']\n",
    "app_test = app_test[app_test['CODE_GENDER'] != 'XNA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1a1LL7nVylI"
   },
   "source": [
    "Pour la variable 'NAME_INCOME_TYPE' :\n",
    "La colonne 'NAME_INCOME_TYPE' prend la valeur 'Maternity leave' uniquement pour le jeu d'entrainement et pour seulement 5 emprunteurs que nous allons supprimé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0gn4RnPWGZX",
    "outputId": "1b12defa-c1e5-477f-a0aa-5b84ae2da77a"
   },
   "outputs": [],
   "source": [
    "app_train['NAME_INCOME_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cg7MooP-V4VW",
    "outputId": "6f1ba87b-a1cf-47ca-851a-95dc457f69f6"
   },
   "outputs": [],
   "source": [
    "app_test['NAME_INCOME_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Akt8r00UV0g7"
   },
   "outputs": [],
   "source": [
    "# Supprime les individus dont 'NAME_INCOME_TYPE' vient d'un congé maternité\n",
    "#app_train = app_train[app_train['NAME_INCOME_TYPE'] != 'Maternity leave']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW8D5oj2W7Yu"
   },
   "source": [
    " Pour la colonne NAME_FAMILY_STATUS, il y a seulement deux fois la valeur Unknown et uniquement pour le jeu d'entrainement. Les lignes correspondantes sont supprimées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgKP270YW6Nf",
    "outputId": "27c0c0b8-dff0-4e17-c6ca-6ebf1f45f8bd"
   },
   "outputs": [],
   "source": [
    "app_train['NAME_FAMILY_STATUS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq0fUgpZW6cL",
    "outputId": "263ce60f-6cec-459e-8e4d-1e34962db58a"
   },
   "outputs": [],
   "source": [
    "app_test['NAME_FAMILY_STATUS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtOrykc1XJMR"
   },
   "outputs": [],
   "source": [
    "# Supprime les individus dont la statut familial est inconnu\n",
    "app_train = app_train[app_train['NAME_FAMILY_STATUS'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "iiVJkr-da4S0",
    "outputId": "469996e6-0d24-4411-9102-1cac2efcb6a4"
   },
   "outputs": [],
   "source": [
    "(fig, ax) = plt.subplots(figsize=(12, 5))\n",
    "plt.title(\"Les professions les plus représentées \\n\")\n",
    "sns.countplot(data=app_train, x=app_train[\"OCCUPATION_TYPE\"],  color=\"#b541a4\")\n",
    "plt.xticks(range(0,app_train[\"OCCUPATION_TYPE\"].nunique()+1) ,app_train[\"OCCUPATION_TYPE\"].unique(),rotation=90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v9XzFjuPdST"
   },
   "source": [
    "### Alignement des données de train et de test\n",
    "Il doit y avoir les mêmes caractéristiques (colonnes) dans les données de formation et de test. L'encodage à chaud a créé plus de colonnes dans les données d'apprentissage car il y avait des variables catégorielles avec des catégories non représentées dans les données de test. Pour supprimer les colonnes des données d'entraînement qui ne figurent pas dans les données de test, nous devons aligner les dataframes. Nous extrayons d'abord la colonne cible des données d'apprentissage (car cela ne figure pas dans les données de test, mais nous devons conserver ces informations). Lorsque nous faisons l'alignement, nous devons nous assurer de définir axis = 1 pour aligner les dataframes en fonction des colonnes et non des lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3EuttUlNZfw",
    "outputId": "ff651166-7d0c-4ab5-a26d-307a247f3939"
   },
   "outputs": [],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_JFg3rVQPmY"
   },
   "source": [
    "### Traitement des outliers\n",
    "### Anomalies\n",
    "Numéros mal saisis, erreurs dans l'équipement de mesure ou mesures extrêmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-SSBb6sRke8",
    "outputId": "960df5c7-2b90-4203-c437-ad3d5a3ee652"
   },
   "outputs": [],
   "source": [
    "(app_train['DAYS_BIRTH'] / -365).describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO8fc7VBRzVH"
   },
   "source": [
    "Il n'y a pas de valeurs aberrantes pour l'âge, que ce soit à l'extrémité supérieure ou inférieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hPqX8r7PvDM",
    "outputId": "f328d47d-f243-42fd-b32e-b7f28f2f9e98"
   },
   "outputs": [],
   "source": [
    "(app_train['DAYS_EMPLOYED'] / -365).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "C1V4wa6URfyi",
    "outputId": "829c792c-2369-43aa-be6c-122a45aa7c51"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram', color = \"green\", label='Train_DAYS_EMPLOYED')\n",
    "app_test['DAYS_EMPLOYED'].plot.hist(color = \"yellow\", label='Test_DAYS_EMPLOYED')\n",
    "plt.xlabel('Days Employment')\n",
    "plt.legend()\n",
    "app_test['DAYS_EMPLOYED'][app_test['DAYS_EMPLOYED'] > 200000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UOkBGg6Stpg"
   },
   "source": [
    "sous-divisons les clients anormaux et voyons s'ils ont tendance à avoir des taux de défaut plus élevés ou plus faibles que le reste des clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LjdJy0k3SCUe",
    "outputId": "fca8aca9-65f8-4154-80cb-d807d55d17c7"
   },
   "outputs": [],
   "source": [
    "anom = app_train[app_train['DAYS_EMPLOYED'] == 365243]\n",
    "non_anom = app_train[app_train['DAYS_EMPLOYED'] != 365243]\n",
    "print('The non-anomalies default on %0.2f%% of loans' % (100 * non_anom['TARGET'].mean()))\n",
    "print('The anomalies default on %0.2f%% of loans' % (100 * anom['TARGET'].mean()))\n",
    "print('There are %d anomalous days of employment' % len(anom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UTcon1mUBCa"
   },
   "source": [
    "Il s'avère que les anomalies ont un taux de défaut plus faible. Nous allons remplir les valeurs anormales sans nombre (np.nan) puis créer une nouvelle colonne booléenne indiquant si la valeur était anormale ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "zqodv_gzSyAu",
    "outputId": "f69a16e8-0295-4580-c258-621ac5e8a593"
   },
   "outputs": [],
   "source": [
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram',color = \"green\", label='Train_DAYS_EMPLOYED')\n",
    "app_test['DAYS_EMPLOYED'].plot.hist(color = \"yellow\", label='Test_DAYS_EMPLOYED')\n",
    "plt.xlabel('Days Employment')\n",
    "plt.legend()\n",
    "\n",
    "print('Il y a %d anomalies dans les données de test sur %d entrées\\n' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8r8ZyaKa4b2"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde des données non encore encodées\n",
    "\n",
    "\n",
    "app_train.to_csv('app_train_no_encoded_no_featureengineering.csv', index=False)\n",
    "app_test.to_csv('app_test_no_encoded_no_featureengineering.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHTjyCQMaRTD"
   },
   "source": [
    "### Effet de l'âge sur le remboursement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26qEQVOaYTA-",
    "outputId": "5a409067-ad12-416a-8cb5-923c37a2d2d5"
   },
   "outputs": [],
   "source": [
    "# Find the correlation of the positive days since birth and target\n",
    "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\n",
    "app_train['DAYS_BIRTH'].corr(app_train['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PuM9WBwf0L3"
   },
   "source": [
    "À mesure que le client vieillit, il existe une relation linéaire négative avec la cible, ce qui signifie qu'à mesure que les clients vieillissent, ils ont tendance à rembourser leurs prêts à temps plus souvent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXdAY-c9f5zg"
   },
   "source": [
    "### Répartition de l'âge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "Dps1DO0Gb8X1",
    "outputId": "9f26d562-c6cc-4888-933a-72240d24e449"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of ages in years\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.hist(app_train['DAYS_BIRTH'] / 365, color = '#AEE7F2', edgecolor = 'black', bins = 25)\n",
    "plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "ZqyWnBClgcVj",
    "outputId": "484dcdad-ef39-43f2-a203-42e7ca28b9aa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "# KDE plot of loans that were repaid on time\n",
    "sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target = 0', color = '#458b74')\n",
    "\n",
    "# KDE plot of loans which were not repaid on time\n",
    "sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target = 1',  color = '#dfa801')\n",
    "\n",
    "# Labeling of plot\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Ages')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lpWHdv2p-xv"
   },
   "source": [
    "La courbe cible == 1 s'incline vers l'extrémité la plus jeune de la plage. Bien qu'il ne s'agisse pas d'une corrélation significative (coefficient de corrélation de -0,07), cette variable sera probablement utile dans un modèle d'apprentissage automatique car elle affecte la cible. Regardons cette relation sous un autre angle : incapacité moyenne à rembourser les crédits par tranche d'âge.\n",
    "\n",
    "Pour faire ce graphique, nous avons d'abord découpé la catégorie d'âge en tranches de 5 ans chacune. Ensuite, pour chaque bin, nous calculons la valeur moyenne de la cible, qui nous indique le ratio de prêts non remboursés dans chaque catégorie d'âge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "W8832_vBi2Io",
    "outputId": "1f995a00-6d6e-410f-c72a-21d601c6a031"
   },
   "outputs": [],
   "source": [
    "# Age information into a separate dataframe\n",
    "age_data = app_train[['TARGET', 'DAYS_BIRTH']]\n",
    "age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365\n",
    "\n",
    "# Bin the age data\n",
    "age_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\n",
    "age_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "AzYJmAGxqUxE",
    "outputId": "473a4888-3048-4a5f-fa38-a2d19082fb39"
   },
   "outputs": [],
   "source": [
    "# Group by the bin and calculate averages\n",
    "age_groups  = age_data.groupby('YEARS_BINNED').mean()\n",
    "age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "feet6keUqi3R",
    "outputId": "f1fa9435-4df8-4482-9c08-f3464c489c46"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "# Graph the age bins and the average of the target as a bar plot\n",
    "plt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'], color = '#ae639b')\n",
    "\n",
    "# Plot labeling\n",
    "plt.xticks(rotation = 35)\n",
    "plt.xlabel('Group age(years)')\n",
    "plt.ylabel('Défaut de remboursement (%)')\n",
    "plt.title(\"Défaut de remboursement par groupe d'âge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uuW2axMrmUL"
   },
   "source": [
    " les jeunes demandeurs sont plus susceptibles de ne pas rembourser le prêt ! Le taux d'impayés est supérieur à 10 % pour les trois tranches d'âge les plus jeunes et inférieur à 5 % pour la tranche d'âge la plus élevée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDUHHunQsI9d"
   },
   "source": [
    "### Sources extérieures\n",
    "Les 3 variables avec les plus fortes corrélations négatives avec Target sont EXT_SOURCE_1, EXT_SOURCE_2,  EXT_SOURCE_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9buJnKJnq4Zt",
    "outputId": "e142e982-4c8b-4730-9fe9-d016fb6eddee"
   },
   "outputs": [],
   "source": [
    "ext_data = app_train[['TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
    "ext_data_corrs = ext_data.corr()\n",
    "ext_data_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "uYynE5s3sdfX",
    "outputId": "265f4504-c4cd-4a1f-cafd-1b493dfeec64"
   },
   "outputs": [],
   "source": [
    "# Heatmap of correlations\n",
    "plt.figure(figsize = (10, 8))\n",
    "#mask = np.triu(ext_data_corrs)\n",
    "\n",
    "sns.heatmap(ext_data_corrs,  cmap='BrBG', vmin = -0.3, annot = True, vmax = 1)\n",
    "plt.title('Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ozxQBkCtlsv"
   },
   "source": [
    "\n",
    "Les trois caractéristiques EXT_SOURCE ont des corrélations négatives avec la cible, ce qui indique qu'à mesure que la valeur de EXT_SOURCE augmente, le client est plus susceptible de rembourser le prêt. Nous pouvons également voir que DAYS_BIRTH est positivement corrélé avec EXT_SOURCE_1 indiquant que peut-être l'un des facteurs de ce score est l'âge du client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRimQ1Nz63Ci"
   },
   "source": [
    "EXT_SOURCE_3 affiche la plus grande différence entre les valeurs de la cible, cette caractéristique a une certaine relation avec la probabilité qu'un demandeur rembourse un prêt. La relation n'est pas très forte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBTw7KFXwSXy"
   },
   "source": [
    "# Feature Engineering\n",
    "CREDIT_INCOME_PERCENT: \n",
    "le pourcentage du montant du crédit par rapport au revenu d'un client\n",
    "\n",
    "ANNUITY_INCOME_PERCENT: le pourcentage de l'annuité du prêt par rapport au revenu du client\n",
    "\n",
    "CREDIT_TERM: la durée du paiement en mois (puisque l'annuité est le montant mensuel dû\n",
    "\n",
    "DAYS_EMPLOYED_PERCENT: le pourcentage des jours employés par rapport à l'âge du client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y0gf3foaEre0",
    "outputId": "f5b8daf4-ac72-4e9d-edcf-0693e5fc4383"
   },
   "outputs": [],
   "source": [
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "\n",
    "app_train_domain['INCOME_TO_ANNUITY_RATIO'] = app_train_domain['AMT_INCOME_TOTAL'] / app_train_domain['AMT_ANNUITY']\n",
    "app_train_domain['INCOME_TO_ANNUITY_RATIO_BY_AGE'] = app_train_domain['INCOME_TO_ANNUITY_RATIO'] * app_train_domain['DAYS_BIRTH']\n",
    "app_train_domain['INCOME_PER_PERSON'] = app_train_domain['AMT_INCOME_TOTAL'] / app_train_domain['CNT_FAM_MEMBERS']\n",
    "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
    "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']\n",
    "app_train_domain['PAYMENT_RATE'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
    "\n",
    "\n",
    "app_test_domain['INCOME_TO_ANNUITY_RATIO'] = app_test_domain['AMT_INCOME_TOTAL'] / app_test_domain['AMT_ANNUITY']\n",
    "app_test_domain['INCOME_TO_ANNUITY_RATIO_BY_AGE'] = app_test_domain['INCOME_TO_ANNUITY_RATIO'] * app_test_domain['DAYS_BIRTH']\n",
    "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
    "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']\n",
    "app_test_domain['INCOME_PER_PERSON'] = app_test_domain['AMT_INCOME_TOTAL'] / app_test_domain['CNT_FAM_MEMBERS']\n",
    "app_test_domain['PAYMENT_RATE'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
    "\n",
    "plt.figure(figsize = (12, 20))\n",
    "# iterate through the new features\n",
    "for i, feature in enumerate(['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']):\n",
    "    \n",
    "    # create a new subplot for each source\n",
    "    plt.subplot(4, 1, i + 1)\n",
    "    # plot repaid loans\n",
    "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 0, feature], label = 'target == 0')\n",
    "    # plot loans that were not repaid\n",
    "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 1, feature], label = 'target == 1')\n",
    "    \n",
    "    # matplotlib.pyplot.legend\n",
    "    # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html\n",
    "    plt.legend()\n",
    "    \n",
    "    # Label the plots\n",
    "    plt.title('Distribution of %s by Target Value' % feature)\n",
    "    plt.xlabel('%s' % feature); plt.ylabel('Density');\n",
    "    \n",
    "plt.tight_layout(h_pad = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4-mWCxkrfzM"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde des résultats\n",
    "app_train_domain.to_csv('app_train_domain_no_enconded_featureengineering.csv', index=False)\n",
    "app_test_domain.to_csv('app_test_domain_no_enconded_featureengineering.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si 'Target' est une colonne dans le DataFrame\n",
    "if 'TARGET' in app_train_domain.columns:\n",
    "    print(\"La variable 'Target' est présente dans le DataFrame.\")\n",
    "else:\n",
    "    print(\"La variable 'Target' n'est pas présente dans le DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCaa4GWSwnrl"
   },
   "source": [
    "# Traitement des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_ = pd.read_csv('app_train_domain_no_enconded_featureengineering.csv', sep=',')\n",
    "app_test_ = pd.read_csv('app_test_domain_no_enconded_featureengineering.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si 'Target' est une colonne dans le DataFrame\n",
    "if 'TARGET' in app_train_.columns:\n",
    "    print(\"La variable 'Target' est présente dans le DataFrame.\")\n",
    "else:\n",
    "    print(\"La variable 'Target' n'est pas présente dans le DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "F6-aJOtVwqCd",
    "outputId": "f0401562-b779-473a-d232-e55267fbb684"
   },
   "outputs": [],
   "source": [
    "missing_values_table(app_train_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KucEpeCzegx"
   },
   "source": [
    "### Suppression des valeurs manquantes de plus 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eq-eS8Po3Toi"
   },
   "outputs": [],
   "source": [
    "# suppression des colonnes avec plus de 90% de valeurs manquantes pour les données d'entrainement\n",
    "app_train_ = app_train_.loc[:, app_train_.isnull().mean() <.90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si 'Target' est une colonne dans le DataFrame\n",
    "if 'TARGET' in app_train_.columns:\n",
    "    print(\"La variable 'Target' est présente dans le DataFrame.\")\n",
    "else:\n",
    "    print(\"La variable 'Target' n'est pas présente dans le DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUEPaAsHBSSS"
   },
   "source": [
    "### Encodage des variables catégorielles\n",
    "Les variables catégorielles doivent être encodés pour être utilisables par les modèles. nous utiliserons Label Encoding pour toutes les variables catégorielles avec seulement 2 catégories et One-Hot Encoding pour toutes les variables catégorielles avec plus de 2 catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Séparation des variables catégorielles et numériques\n",
    "num_var = app_train_.select_dtypes(include=['int64', 'float64'])\n",
    "cat_var = app_train_.select_dtypes(exclude=['int64', 'float64'])\n",
    "\n",
    "# Encodage avec LabelEncoder pour les colonnes avec 2 catégories uniques\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Colonnes à encoder avec One-Hot Encoding\n",
    "one_hot_columns = []\n",
    "\n",
    "# Iterate through the categorical columns\n",
    "for col in cat_var.columns:\n",
    "    if len(app_train_[col].unique()) <= 2:\n",
    "        # Appliquer le label encoder si 2 ou moins catégories\n",
    "        app_train_[col] = le.fit_transform(app_train_[col])\n",
    "        app_test_[col] = le.transform(app_test_[col])\n",
    "        le_count += 1\n",
    "    else:\n",
    "        # Ajouter à la liste pour one-hot encoding si plus de 2 catégories\n",
    "        one_hot_columns.append(col)\n",
    "\n",
    "print(f'{le_count} columns were label encoded.')\n",
    "\n",
    "# Appliquer One-Hot Encoding sur les colonnes restantes\n",
    "app_train_ = pd.get_dummies(app_train_, columns=one_hot_columns, dummy_na=True)\n",
    "app_test_ = pd.get_dummies(app_test_, columns=one_hot_columns, dummy_na=True)\n",
    "\n",
    "# Assurer que les colonnes sont les mêmes entre les jeux d'entraînement et de test\n",
    "app_train_, app_test_ = app_train_.align(app_test_, join='inner', axis=1)\n",
    "\n",
    "# Affichage des trois premières lignes\n",
    "app_train_.head(3)\n",
    "print('Final Training Features shape: ', app_train_.shape)\n",
    "print('Final Testing Features shape: ', app_test_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wz_iXsPJK36c"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde des données\n",
    "app_train_.to_csv('app_train_encoded.csv', index=False)\n",
    "app_test_.to_csv('app_test_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cD3cXkTZNWcm"
   },
   "outputs": [],
   "source": [
    "# Vérifier si 'Target' est une colonne dans le DataFrame\n",
    "if 'TARGET' in app_train_.columns:\n",
    "    print(\"La variable 'Target' est présente dans le DataFrame.\")\n",
    "else:\n",
    "    print(\"La variable 'Target' n'est pas présente dans le DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsX3HQLQBw9t"
   },
   "source": [
    "## Preprocessing et Fusion des tables\n",
    "Les procédures de fusion des tables ci-dessous sont basés sur le pipeline de feature engineering présenté dans :\n",
    "\n",
    "https://www.kaggle.com/code/jsaguiar/lightgbm-with-simple-features/script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    \"\"\" Context manager for timing code execution \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.end = time.time()\n",
    "        print(f\"{self.name} - {self.end - self.start:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    \"\"\" One-hot encode categorical features and handle missing values. \"\"\"\n",
    "    cat_cols = [c for c in df.columns if df[c].dtype == 'object']\n",
    "    if nan_as_category:\n",
    "        for c in cat_cols:\n",
    "            df[c] = df[c].astype(str).fillna('NAN')\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "    return df, [col for col in df.columns if col.startswith(tuple(cat_cols))]\n",
    "\n",
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    \"\"\" Preprocess bureau.csv and bureau_balance.csv \"\"\"\n",
    "    bureau = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\bureau.csv', nrows=num_rows)\n",
    "    print(f'Read bureau samples: {len(bureau)} rows, {len(bureau.columns)} columns')\n",
    "    \n",
    "    bureau_balance = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\bureau_balance.csv', nrows=num_rows)\n",
    "    print(f'Read bureau balance samples: {len(bureau_balance)} rows, {len(bureau_balance.columns)} columns')\n",
    "\n",
    "    bureau_balance, bureau_balance_cat = one_hot_encoder(bureau_balance, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "\n",
    "    # Perform aggregations and merge with bureau.csv\n",
    "    bureau_balance_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bureau_balance_cat:\n",
    "        bureau_balance_aggregations[col] = ['mean']\n",
    "    \n",
    "    bureau_balance_agg = bureau_balance.groupby('SK_ID_BUREAU').agg(bureau_balance_aggregations)\n",
    "    bureau_balance_agg.columns = pd.Index([f\"{e[0]}_{e[1].upper()}\" for e in bureau_balance_agg.columns.tolist()])\n",
    "    \n",
    "    bureau = bureau.join(bureau_balance_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace=True)\n",
    "    \n",
    "    del bureau_balance, bureau_balance_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "\n",
    "    # Categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    for cat in bureau_balance_cat:\n",
    "        cat_aggregations[f\"{cat}_MEAN\"] = ['mean']\n",
    "\n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index([f\"BURO_{e[0]}_{e[1].upper()}\" for e in bureau_agg.columns.tolist()])\n",
    "\n",
    "    # Active and Closed credits\n",
    "    for status in ['Active', 'Closed']:\n",
    "        subset = bureau[bureau[f'CREDIT_ACTIVE_{status}'] == 1]\n",
    "        subset_agg = subset.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        subset_agg.columns = pd.Index([f\"{status.upper()}_{e[0]}_{e[1].upper()}\" for e in subset_agg.columns.tolist()])\n",
    "        bureau_agg = bureau_agg.join(subset_agg, how='left', on='SK_ID_CURR')\n",
    "        del subset, subset_agg\n",
    "    \n",
    "    del bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg\n",
    "\n",
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    \"\"\" Preprocess previous_application.csv \"\"\"\n",
    "    app_previous = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\previous_application.csv', nrows=num_rows)\n",
    "    print(f'Read previous application samples: {len(app_previous)} rows, {len(app_previous.columns)} columns')\n",
    "    \n",
    "    app_previous, cat_cols = one_hot_encoder(app_previous, nan_as_category=True)\n",
    "    \n",
    "    # Handle specific missing value replacement\n",
    "    for col in ['DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION']:\n",
    "        app_previous[col].replace(365243, np.nan, inplace=True)\n",
    "    \n",
    "    # Add feature\n",
    "    app_previous['APP_CREDIT_PERC'] = app_previous['AMT_APPLICATION'] / app_previous['AMT_CREDIT']\n",
    "    \n",
    "    # Numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum']\n",
    "    }\n",
    "\n",
    "    # Categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    app_previous_agg = app_previous.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    app_previous_agg.columns = pd.Index([f\"PREV_{e[0]}_{e[1].upper()}\" for e in app_previous_agg.columns.tolist()])\n",
    "\n",
    "    # Approved and Refused applications\n",
    "    for status in ['Approved', 'Refused']:\n",
    "        subset = app_previous[app_previous[f'NAME_CONTRACT_STATUS_{status}'] == 1]\n",
    "        subset_agg = subset.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        subset_agg.columns = pd.Index([f\"{status.upper()}_{e[0]}_{e[1].upper()}\" for e in subset_agg.columns.tolist()])\n",
    "        app_previous_agg = app_previous_agg.join(subset_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    del app_previous\n",
    "    gc.collect()\n",
    "    return app_previous_agg\n",
    "\n",
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    \"\"\" Preprocess POS_CASH_balance.csv \"\"\"\n",
    "    pos = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\POS_CASH_balance.csv', nrows=num_rows)\n",
    "    print(f'Read POS cash balance samples: {len(pos)} rows, {len(pos.columns)} columns')\n",
    "    \n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category=True)\n",
    "\n",
    "    # Aggregations\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "\n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index([f\"POS_{e[0]}_{e[1].upper()}\" for e in pos_agg.columns.tolist()])\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "\n",
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    \"\"\" Preprocess installments_payments.csv \"\"\"\n",
    "    ins = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\installments_payments.csv', nrows=num_rows)\n",
    "    print(f'Read installments payments samples: {len(ins)} rows, {len(ins.columns)} columns')\n",
    "    \n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category=True)\n",
    "\n",
    "    # Feature Engineering\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: max(x, 0))\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: max(x, 0))\n",
    "\n",
    "    # Aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index([f\"INSTAL_{e[0]}_{e[1].upper()}\" for e in ins_agg.columns.tolist()])\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    \"\"\" Preprocess credit_card_balance.csv \"\"\"\n",
    "    cc = pd.read_csv(r'C:\\\\Users\\\\saidi\\\\Projet_7\\\\Data\\\\credit_card_balance.csv', nrows=num_rows)\n",
    "    print(f'Read credit card balance samples: {len(cc)} rows, {len(cc.columns)} columns')\n",
    "    \n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=True)\n",
    "    \n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis=1, inplace=True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index([f\"CC_{e[0]}_{e[1].upper()}\" for e in cc_agg.columns.tolist()])\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg\n",
    "\n",
    "def preprocess_pipeline(num_rows=None, debug=False):\n",
    "    \"\"\" Main preprocessing pipeline \"\"\"\n",
    "    df = pd.read_csv('app_train_encoded.csv')  # Replace with actual path\n",
    "    start = time.time()\n",
    "\n",
    "    with Timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "\n",
    "    with Timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "\n",
    "    with Timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "\n",
    "    with Timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "\n",
    "    with Timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "\n",
    "    time_taken = time.time() - start\n",
    "    print(f'Preprocessing completed in {time_taken:.0f} s')\n",
    "    return df\n",
    "\n",
    "# File names and paths\n",
    "RAW_DATA_FILENAME = 'HomeCredit_columns_description.csv'\n",
    "CLEAN_DATA_FILENAME = 'cleaned_data_scoring.csv'\n",
    "CLEAN_DATA_SAMPLE = 'cleaned_data_sample.csv'  # 100,000 records\n",
    "CLEAN_DATA_FEATURES = 'cleaned_data_features.csv'  # Top 100 features\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "savepath = CLEAN_DATA_FILENAME\n",
    "\n",
    "if os.path.exists(savepath):\n",
    "    print('Reloading preprocessed_data (preprocess pipeline has not been modified since last edit)')\n",
    "    df_data = pd.read_csv(savepath)\n",
    "else:\n",
    "    df_data = preprocess_pipeline(num_rows=None, debug=False)\n",
    "    df_data.to_csv(savepath, index=False)\n",
    "\n",
    "print(f'df_data.shape = {df_data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_columns_with_infinite_values(df):\n",
    "    \"\"\" Detect columns with infinite values and count them. \"\"\"\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Find columns with infinite values\n",
    "    inf_cols = numeric_df.columns[np.isinf(numeric_df).any()]\n",
    "    \n",
    "    res = []\n",
    "    for col in inf_cols:\n",
    "        inf_rows = np.isinf(numeric_df[col]).sum()\n",
    "        res.append({'colonne': col, 'inf_count': inf_rows})\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def replace_infinite_values(df):\n",
    "    \"\"\" Replace infinite values with NaN. \"\"\"\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Replace positive and negative infinity with NaN in numeric columns\n",
    "    df[numeric_df.columns] = numeric_df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Get columns with infinite values\n",
    "inf_summary = get_columns_with_infinite_values(df_data)\n",
    "print(\"Columns with infinite values:\")\n",
    "print(inf_summary)\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "df_data_cleaned = replace_infinite_values(df_data)\n",
    "\n",
    "# Optionally, save the cleaned DataFrame\n",
    "# df_data_cleaned.to_csv('cleaned_data_with_nan.csv', index=False)\n",
    "\n",
    "# Verify the replacement\n",
    "inf_summary_after = get_columns_with_infinite_values(df_data_cleaned)\n",
    "print(\"Columns with infinite values after replacement:\")\n",
    "print(inf_summary_after)\n",
    "print(f'les valeurs infinite ont bien remplacé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "PSVMDl7o18p4",
    "outputId": "990c7fb7-4c21-40a7-cb93-27a073cf054f"
   },
   "outputs": [],
   "source": [
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FobqCZSwY_Ny"
   },
   "source": [
    "On voit qu'il y a les colonnes avec seulement une valeur et puisque l'imputation pour les modèles donne une variable qui est constante et le coefficient de correlation sera NaN, donc on va les supprimer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4S4XtNMCS8g9",
    "outputId": "7da45b8a-e7da-44a5-9c82-41a117ec9dcb"
   },
   "outputs": [],
   "source": [
    "def get_single_value_cols(df: pd.DataFrame):\n",
    "    unique_vals = df.nunique()\n",
    "    return unique_vals[unique_vals == 1].index.to_list()\n",
    "\n",
    "def drop_single_value_cols(df: pd.DataFrame, cols_to_drop=None):\n",
    "    if cols_to_drop is None:\n",
    "        cols_to_drop = get_single_value_cols(df)\n",
    "    if len(cols_to_drop) > 0:\n",
    "        print(f'supprimer les colonnes avec seulement une valeur, nb.cols = {len(cols_to_drop)}')\n",
    "        return df.drop(columns=cols_to_drop)\n",
    "    return df\n",
    "\n",
    "df_data = drop_single_value_cols(df_data)\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6skmF37E4oA"
   },
   "outputs": [],
   "source": [
    "df_data.to_csv('data_clean.csv', index=False)\n",
    "app_train_domain.to_csv('data_train.csv', index=False)\n",
    "app_test_domain.to_csv('data_test.csv', index=False)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si 'Target' est une colonne dans le DataFrame\n",
    "if 'Target' in df_data.columns:\n",
    "    print(\"La variable 'Target' est présente dans le DataFrame.\")\n",
    "else:\n",
    "    print(\"La variable 'Target' n'est pas présente dans le DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
